{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humpback Whale Identifaction -- public kernels summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Some Exploration, including inspiration of data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "INPUT_DIR = '../input'\n",
    "\n",
    "def plot_images_for_filenames(filenames, labels, rows=4):\n",
    "    imgs = [plt.imread(f'{INPUT_DIR}/train/{filename}') for filename in filenames]\n",
    "    \n",
    "    return plot_images(imgs, labels, rows)\n",
    "    \n",
    "        \n",
    "def plot_images(imgs, labels, rows=4):\n",
    "    # Set figure to 13 inches x 8 inches\n",
    "    figure = plt.figure(figsize=(13, 8))\n",
    "\n",
    "    cols = len(imgs) // rows + 1\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        subplot = figure.add_subplot(rows, cols, i + 1)\n",
    "        subplot.axis('Off')\n",
    "        if labels:\n",
    "            subplot.set_title(labels[i], fontsize=16)\n",
    "        plt.imshow(imgs[i], cmap='gray')\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = len(train_df['Id'].unique())\n",
    "     \n",
    "print(f'Number of categories: {num_categories}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(range(len(size_buckets)), list(size_buckets.values())[::-1], align='center')\n",
    "plt.xticks(range(len(size_buckets)), list(size_buckets.keys())[::-1])\n",
    "plt.title(\"Num of categories by images in the training set\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image_ids = train_df['Id'].value_counts().tail(8).keys()\n",
    "one_image_filenames = []\n",
    "labels = []\n",
    "for i in one_image_ids:\n",
    "    one_image_filenames.extend(list(train_df[train_df['Id'] == i]['Image']))\n",
    "    labels.append(i)\n",
    "    \n",
    "plot_images_for_filenames(one_image_filenames, labels, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes = Counter([Image.open(f'{INPUT_DIR}/train/{i}').size for i in train_df['Image']])\n",
    "\n",
    "size, freq = zip(*Counter({i: v for i, v in img_sizes.items() if v > 1}).most_common(20))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.bar(range(len(freq)), list(freq), align='center')\n",
    "plt.xticks(range(len(size)), list(size), rotation=70)\n",
    "plt.title(\"Image size frequencies (where freq > 1)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import (\n",
    "    random_rotation, random_shift, random_shear, random_zoom,\n",
    "    random_channel_shift, transform_matrix_offset_center, img_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "intermediate_tensor_function = K.function([model.layers[0].input],[model.layers[layer_of_interest].output])\n",
    "intermediate_tensor = intermediate_tensor_function([thisInput])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [\n",
    "    random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n",
    "    for _ in range(5)]\n",
    "plot_images(imgs, None, rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [\n",
    "    random_zoom(img_arr, zoom_range=(1.5, 0.7), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest') * 255\n",
    "    for _ in range(5)]\n",
    "plot_images(imgs, None, rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_greyscale(img, p):\n",
    "    if random.random() < p:\n",
    "        return np.dot(img[...,:3], [0.299, 0.587, 0.114])\n",
    "    \n",
    "    return img\n",
    "\n",
    "imgs = [\n",
    "    random_greyscale(img_arr, 0.5) * 255\n",
    "    for _ in range(5)]\n",
    "\n",
    "plot_images(imgs, None, rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_pipeline(img_arr):\n",
    "    img_arr = random_rotation(img_arr, 18, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_shear(img_arr, intensity=0.4, row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_zoom(img_arr, zoom_range=(0.9, 2.0), row_axis=0, col_axis=1, channel_axis=2, fill_mode='nearest')\n",
    "    img_arr = random_greyscale(img_arr, 0.4)\n",
    "\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [augmentation_pipeline(img_arr) * 255 for _ in range(5)]\n",
    "plot_images(imgs, None, rows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A model also inspiring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = len(y_cat.toarray()[0])\n",
    "epochs = 9\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(48, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(48, (3, 3), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(48, (5, 5), activation='sigmoid'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.33))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(36, activation='sigmoid'))\n",
    "model.add(Dropout(0.33))\n",
    "model.add(Dense(36, activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit_generator(image_gen.flow(x_train, y_train.toarray(), batch_size=batch_size),\n",
    "          steps_per_epoch=  x_train.shape[0]//batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          class_weight=class_weight_dic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Some methods for tackling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_image_ids = train_df['Id'].value_counts().tail(8).keys()\n",
    "one_image_filenames = []\n",
    "labels = []\n",
    "for i in one_image_ids:\n",
    "    one_image_filenames.extend(list(train_df[train_df['Id'] == i]['Image']))\n",
    "    labels.append(i)\n",
    "    \n",
    "plot_images_for_filenames(one_image_filenames, labels, rows=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A way to improve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob.glob(\"Whales/test/*.jpg\")\n",
    "l_image_name_test = [test_files[i].split('\\\\')[1] for i in range(len(test_files))]\n",
    "l_class_data = [data['Id'][i] for i in range(len(data))]               # data = file \"train.csv\"\n",
    "\n",
    "# test_preds = predict of inference model for test images (data = for \"train.csv\" images)\n",
    "test_image_dist_all = euclidean_distances(test_preds, data_preds)      \n",
    "preds_str = []\n",
    "\n",
    "\n",
    "for ind in range(len(l_image_name_test)) :\n",
    "    test_image_dist = test_image_dist_all[ind]     # distances between the test image and all the 'train.csv' images\n",
    "    vect_dist = [(l_class_data[i],test_image_dist[i]) for i in range(len(test_image_dist))]    # create list of couples (class, distance)\n",
    "    vect_dist.append((\"new_whale\", 0.0))  # add \"new_whale\" ecach time\n",
    "    vect_dist.sort(key=lambda x: x[1])    # sort  in order to have first the nearest\n",
    "    vect_dist = vect_dist[0:50]            # best 50 nearest \n",
    "    \n",
    "    vect_classes = [vect_dist[i][0] for i in range(len(vect_dist))]\n",
    "    # Maintain only one occurrence per class\n",
    "    vect_result = [vect_dist[0]] + [vect_dist[i] for i in range(1,len(vect_dist)) if vect_classes[i] not in vect_classes[0:i]]\n",
    "    vect_result = vect_result[:5]   # take fist 5 nearest\n",
    "    preds_str.append(\" \".join([x[0] for x in vect_result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Another model but return no result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, merge\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "from keras import optimizers, losses, activations, models\n",
    "from keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, \\\n",
    "    GlobalMaxPool2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.neighbors import NearestNeighbors  \n",
    "\n",
    "class sample_gen(object):\n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):\n",
    "        self.file_class_mapping= file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "\n",
    "        for file, class_ in file_class_mapping.items():\n",
    "            if class_ == other_class:\n",
    "                self.list_other_class.append(file)\n",
    "            else:\n",
    "                self.class_to_list_files[class_].append(file)\n",
    "\n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))\n",
    "        self.range_list_classes= range(len(self.list_classes))\n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes])\n",
    "        self.class_weight = self.class_weight/np.sum(self.class_weight)\n",
    "\n",
    "    def get_sample(self):\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "        positive_example_1, positive_example_2 = \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]],\\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "\n",
    "\n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == \\\n",
    "                self.file_class_mapping[positive_example_1]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 8\n",
    "input_shape = (256, 256)\n",
    "base_path = \"../input/train/\"\n",
    "def identity_loss(y_true, y_pred):\n",
    "\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "\n",
    "def bpr_triplet_loss(X):\n",
    "\n",
    "    positive_item_latent, negative_item_latent, user_latent = X\n",
    "\n",
    "    # BPR loss\n",
    "    loss = 1.0 - K.sigmoid(\n",
    "        K.sum(user_latent * positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(user_latent * negative_item_latent, axis=-1, keepdims=True))\n",
    "\n",
    "    return loss\n",
    "\n",
    "def get_base_model():\n",
    "    latent_dim = 50\n",
    "    base_model = ResNet50(include_top=False) # use weights='imagenet' locally\n",
    "\n",
    "    # for layer in base_model.layers:\n",
    "    #     layer.trainable = False\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    dense_1 = Dense(latent_dim)(x)\n",
    "    normalized = Lambda(lambda  x: K.l2_normalize(x,axis=1))(dense_1)\n",
    "    base_model = Model(base_model.input, normalized, name=\"base_model\")\n",
    "    return base_model\n",
    "\n",
    "def build_model():\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_name = \"triplet_model\"\n",
    "\n",
    "file_path = model_name + \"weights.best.hdf5\"\n",
    "\n",
    "\n",
    "\n",
    "def build_inference_model(weight_path=file_path):\n",
    "    base_model = get_base_model()\n",
    "\n",
    "    positive_example_1 = Input(input_shape+(3,) , name='positive_example_1')\n",
    "    negative_example = Input(input_shape+(3,), name='negative_example')\n",
    "    positive_example_2 = Input(input_shape+(3,), name='positive_example_2')\n",
    "\n",
    "    positive_example_1_out = base_model(positive_example_1)\n",
    "    negative_example_out = base_model(negative_example)\n",
    "    positive_example_2_out = base_model(positive_example_2)\n",
    "\n",
    "    loss = merge(\n",
    "        [positive_example_1_out, negative_example_out, positive_example_2_out],\n",
    "        mode=bpr_triplet_loss,\n",
    "        name='loss',\n",
    "        output_shape=(1, ))\n",
    "\n",
    "    model = Model(\n",
    "        input=[positive_example_1, negative_example, positive_example_2],\n",
    "        output=loss)\n",
    "    model.compile(loss=identity_loss, optimizer=Adam(0.000001))\n",
    "\n",
    "    model.load_weights(weight_path)\n",
    "\n",
    "    inference_model = Model(base_model.get_input_at(0), output=base_model.get_output_at(0))\n",
    "    inference_model.compile(loss=\"mse\", optimizer=Adam(0.000001))\n",
    "    print(inference_model.summary())\n",
    "\n",
    "    return inference_model\n",
    "\n",
    "def read_and_resize(filepath):\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize(input_shape)\n",
    "    im_array = np.array(im, dtype=\"uint8\")[..., ::-1]\n",
    "    return np.array(im_array / (np.max(im_array)+ 0.001), dtype=\"float32\")\n",
    "\n",
    "\n",
    "def augment(im_array):\n",
    "    if np.random.uniform(0, 1) > 0.9:\n",
    "        im_array = np.fliplr(im_array)\n",
    "    return im_array\n",
    "\n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = read_and_resize(base_path+positive_example_1), \\\n",
    "                                                                       read_and_resize(base_path+negative_example), \\\n",
    "                                                                       read_and_resize(base_path+positive_example_2)\n",
    "\n",
    "            positive_example_1_img, negative_example_img, positive_example_2_img = augment(positive_example_1_img), \\\n",
    "                                                                                   augment(negative_example_img), \\\n",
    "                                                                                   augment(positive_example_2_img)\n",
    "\n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "\n",
    "        list_positive_examples_1 = np.array(list_positive_examples_1)\n",
    "        list_negative_examples = np.array(list_negative_examples)\n",
    "        list_positive_examples_2 = np.array(list_positive_examples_2)\n",
    "        yield [list_positive_examples_1, list_negative_examples, list_positive_examples_2], np.ones(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Read data\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "train, test = train_test_split(data, test_size=0.3, shuffle=True, random_state=1337)\n",
    "file_id_mapping_train = {k: v for k, v in zip(train.Image.values, train.Id.values)}\n",
    "file_id_mapping_test = {k: v for k, v in zip(test.Image.values, test.Id.values)}\n",
    "train_gen = sample_gen(file_id_mapping_train)\n",
    "test_gen = sample_gen(file_id_mapping_test)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare the test triplets\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "\n",
    "#model.load_weights(file_path)\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
    "\n",
    "callbacks_list = [checkpoint, early]  # early\n",
    "\n",
    "history = model.fit_generator(gen(train_gen), validation_data=gen(test_gen), epochs=3, verbose=2, workers=4, use_multiprocessing=True,\n",
    "                              callbacks=callbacks_list, steps_per_epoch=300, validation_steps=30)\n",
    "                              \n",
    "                              \n",
    "model_name = \"triplet_loss\"\n",
    "def data_generator(fpaths, batch=16):\n",
    "    i = 0\n",
    "    for path in fpaths:\n",
    "        if i == 0:\n",
    "            imgs = []\n",
    "            fnames = []\n",
    "        i += 1\n",
    "        img = read_and_resize(path)\n",
    "        imgs.append(img)\n",
    "        fnames.append(os.path.basename(path))\n",
    "        if i == batch:\n",
    "            i = 0\n",
    "            imgs = np.array(imgs)\n",
    "            yield fnames, imgs\n",
    "    if i < batch:\n",
    "        imgs = np.array(imgs)\n",
    "        yield fnames, imgs\n",
    "    raise StopIteration()\n",
    "\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "\n",
    "file_id_mapping = {k: v for k, v in zip(data.Image.values, data.Id.values)}\n",
    "\n",
    "inference_model = build_inference_model()\n",
    "\n",
    "train_files = glob.glob(\"../input/train/*.jpg\")\n",
    "test_files = glob.glob(\"../input/test/*.jpg\")\n",
    "\n",
    "train_preds = []\n",
    "train_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(train_files, batch=32):\n",
    "    print(i*32/len(train_files)*100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    train_file_names += fnames\n",
    "\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "test_preds = []\n",
    "test_file_names = []\n",
    "i = 1\n",
    "for fnames, imgs in data_generator(test_files, batch=32):\n",
    "    print(i * 32 / len(test_files) * 100)\n",
    "    i += 1\n",
    "    predicts = inference_model.predict(imgs)\n",
    "    predicts = predicts.tolist()\n",
    "    test_preds += predicts\n",
    "    test_file_names += fnames\n",
    "\n",
    "test_preds = np.array(test_preds)\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)\n",
    "#distances, neighbors = neigh.kneighbors(train_preds)\n",
    "\n",
    "#print(distances, neighbors)\n",
    "\n",
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()\n",
    "\n",
    "preds_str = []\n",
    "\n",
    "for filepath, distance, neighbour_ in zip(test_file_names, distances_test, neighbors_test):\n",
    "    sample_result = []\n",
    "    sample_classes = []\n",
    "    for d, n in zip(distance, neighbour_):\n",
    "        train_file = train_files[n].split(os.sep)[-1]\n",
    "        class_train = file_id_mapping[train_file]\n",
    "        sample_classes.append(class_train)\n",
    "        sample_result.append((class_train, d))\n",
    "\n",
    "    if \"new_whale\" not in sample_classes:\n",
    "        sample_result.append((\"new_whale\", 0.1))\n",
    "    sample_result.sort(key=lambda x: x[1])\n",
    "    sample_result = sample_result[:5]\n",
    "    preds_str.append(\" \".join([x[0] for x in sample_result]))\n",
    "\n",
    "df = pd.DataFrame(preds_str, columns=[\"Id\"])\n",
    "df['Image'] = [x.split(os.sep)[-1] for x in test_file_names]\n",
    "df.to_csv(\"sub_%s.csv\"%model_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
